The program works sometimes and crashes other times... 
If you run the full set of data, it's guaranteed to crash at some point. 
I ran a performance test, and, as expected, the majority of the time is 
taken running a chi2 fit... and there's 100 iterations for each temperature. 
Specifically, roughly 66% of the time is spent in fdjac2_ (part of the chi2
fitting), and 33% in Analyzer::fcn (the function that defines what we're doing
a chi2 fit to).

While debugging the program, I've gotten multiple errors. For some reason the
program hits a breakpoint right before "double kb = constants["kb"];" without a
reason. If I continue through this breakpoint, the debugger breaks again and
says a heap has been corrupted. I have no idea what that entails.

I can continue through that again and the program will begin running fits (ever so slowly).
I've gotten it to work with a small set of data, sometimes. The entire set of data in
"generatedData.txt" has crashed every time I try it... although it takes a long time to try.
I forgot the error that occurs when this crashes. I'm running it again while writing this,
so that I can include that in this .txt document when it crashes again. I do know that it
crashes during the fitting though (where the program spends most of its time anyway).

I'm hoping that you (Walter) can look over the code and get an idea on how to optimize my code.
I'm assuming it's memory leaks or something, but I really don't have any idea.

EDIT:

Yep, there seem to be some problems with memory allocation. I just ran a trial and i came up with
this error:

Unhandled exception at 0x74E52F71 in TIDLS Analyzer.exe: Microsoft C++ exception: std::bad_alloc at memory location 0x001AF948.

The breakpoint is right before "wa4 = new real[m]" under Analyzer::runFit(). 
Is this because I'm creating "new"variables every time? Do I need to delete 
these before running another iteration? I'll try it.

I can continue through this exception and run more fits though. This isn't the exception 
that completely halted my debugging earlier.

EDIT2:

So I've done some tinkering and all I've added is to delete the "new" pointers every iteration.
I believe I've narrowed down the problem to just bad memory management. 
When I delete the pointers with,

delete [] var;

I get a bunch of corrupted heap exceptions on every iteration. They are arrays, so I would think
this would be the way to delete them, but I guess not. I believe the program thinks I'm deleting
the vars too many times or something with this command because of the heap exceptions.
I would use vectors and bypass this whole problem, but vectors aren't compatible with the chi2 algorithm.
(It's written in C and I think it makes some calls to Fortran.)

When I use,

delete var;

I end up getting bad_alloc exceptions instead... as if the correct thing to do is delete[].


FOUND A CULPRIT:
There is also an initial crash when first starting the program that says,
Critical error detected c0000374

This is a heap overrun/corruption error. Using cout, I've narrowed it down to the Analyzer::tSRH function.
I'm assuming the heap error occurs when we call on the equations pointer. Do you know why this is?